{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4ba4fb9-816e-422f-90c7-ee5cc2baae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment ready.\n",
      "Python: 3.10.2  |  Platform: Linux 5.15.0-1064-aws\n",
      "LangChain: 1.0.3  |  ChromaDB: 1.3.2  |  Gradio: 4.7.1\n",
      "PDF present: True  -> /voc/work/the_nestle_hr_policy_pdf_2012.pdf\n",
      "Token test (hello world): 2\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# STEP 1 â€” ENV + IMPORTS (FINALIZED)\n",
    "# =========================\n",
    "\n",
    "# ---- 1) Install dependencies ----\n",
    "try:\n",
    "    import langchain, chromadb, gradio\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    pkgs = [\n",
    "        \"langchain>=0.2.0\",\n",
    "        \"langchain-core>=0.2.0\",\n",
    "        \"langchain-community>=0.2.0\",\n",
    "        \"langchain-openai>=0.1.0\",\n",
    "        \"langchain-text-splitters>=0.2.0\",\n",
    "        \"chromadb>=0.5.0\",\n",
    "        \"pypdf>=4.0.0\",\n",
    "        \"tiktoken>=0.7.0\",\n",
    "        \"gradio>=4.0.0\",\n",
    "        \"openai>=1.40.0\"\n",
    "    ]\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *pkgs])\n",
    "\n",
    "# ---- 2) API key setup ----\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OPENAI_API_KEY: \")\n",
    "\n",
    "# ---- 3) Imports ----\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import gradio as gr\n",
    "import tiktoken, chromadb, pathlib, sys, platform\n",
    "\n",
    "# ---- 4) Constants ----\n",
    "# âœ… Use a writable directory (avoid permission issues)\n",
    "DATA_DIR = pathlib.Path(\"/mnt/data\") if pathlib.Path(\"/mnt/data\").exists() else pathlib.Path.cwd()\n",
    "PDF_PATH = DATA_DIR / \"the_nestle_hr_policy_pdf_2012.pdf\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "CHAT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "# ---- 5) Sanity checks ----\n",
    "client = OpenAI()\n",
    "print(\"âœ… Environment ready.\")\n",
    "print(f\"Python: {sys.version.split()[0]}  |  Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"LangChain: {langchain.__version__}  |  ChromaDB: {chromadb.__version__}  |  Gradio: {gr.__version__}\")\n",
    "print(f\"PDF present: {PDF_PATH.exists()}  -> {PDF_PATH}\")\n",
    "\n",
    "# Tokenizer test (verifies tiktoken works)\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "print(\"Token test (hello world):\", len(enc.encode(\"hello world\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f76afa9-ca57-4260-aaa0-58c931dc7415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pysqlite3-binary in ./.local/lib/python3.10/site-packages (0.5.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mâœ… Patched sqlite3 with pysqlite3 backend.\n"
     ]
    }
   ],
   "source": [
    "!pip install pysqlite3-binary\n",
    "# ---- Patch SQLite if too old ----\n",
    "try:\n",
    "    import sqlite3\n",
    "    import pysqlite3\n",
    "    import sys\n",
    "    sys.modules[\"sqlite3\"] = sys.modules.pop(\"pysqlite3\")\n",
    "    print(\"âœ… Patched sqlite3 with pysqlite3 backend.\")\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ Could not patch sqlite3, fallback to system version:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "116df355-9c37-4609-8f07-b0c3edfdc567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pysqlite3-binary\n",
      "  Downloading pysqlite3_binary-0.5.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (766 bytes)\n",
      "Downloading pysqlite3_binary-0.5.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pysqlite3-binary\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pysqlite3-binary-0.5.4\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade --force-reinstall \"gradio==4.29.0\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "240e7a80-4153-4030-a416-312587f39902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Loading HR Policy PDF...\n",
      "âœ… Loaded 8 pages from: the_nestle_hr_policy_pdf_2012.pdf\n",
      "\n",
      "--- Sample text snippet ---\n",
      "Policy\n",
      "Mandatory\n",
      "Septemberâ€‰â€‰2012\n",
      "The NestlÃ©  \n",
      "Human Resources Policy \n",
      "\n",
      "âœ… Split into 20 chunks (~68 chars each)\n",
      "\n",
      "ğŸ§© Chunk 1:\n",
      "Policy\n",
      "Mandatory\n",
      "Septemberâ€‰â€‰2012\n",
      "The NestlÃ©  \n",
      "Human Resources Policy...\n",
      "\n",
      "ğŸ§© Chunk 2:\n",
      "Policy\n",
      "Mandatory\n",
      "Septemberâ€‰\n",
      "â€‰20\n",
      "12\n",
      "Issuingâ€‰departement\n",
      "Hum\n",
      "an Resources\n",
      "Targetâ€‰audienceâ€‰\n",
      "All\n",
      " employees\n",
      "Approver\n",
      "Executive Board, NestlÃ© S.A.\n",
      "Repository\n",
      "All NestlÃ© Principles and Policies, Standards and  \n",
      "Guidelines can be found in the Centre online repository at:  \n",
      "http://intranet.nestle.com/nestle...\n",
      "\n",
      "ğŸ’¾ Chunks saved to: /voc/work/hr_policy_chunks.pkl\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# STEP 2 â€” LOAD & SPLIT PDF\n",
    "# =========================\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import pickle\n",
    "\n",
    "# ---- 1) Load the PDF ----\n",
    "print(\"ğŸ“„ Loading HR Policy PDF...\")\n",
    "loader = PyPDFLoader(str(PDF_PATH))\n",
    "documents = loader.load()   # list of Document objects (one per page)\n",
    "print(f\"âœ… Loaded {len(documents)} pages from: {PDF_PATH.name}\")\n",
    "\n",
    "# ---- 2) Inspect first page (optional) ----\n",
    "print(\"\\n--- Sample text snippet ---\")\n",
    "print(documents[0].page_content[:400], \"\\n\")\n",
    "\n",
    "# ---- 3) Split text into smaller chunks ----\n",
    "#   Small chunks improve embedding relevance.\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,       # about 200â€“250 tokens\n",
    "    chunk_overlap=200,     # keep context continuity\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"],\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(documents)\n",
    "print(f\"âœ… Split into {len(chunks)} chunks (~{len(chunks[0].page_content)} chars each)\")\n",
    "\n",
    "# ---- 4) Preview a few chunks (optional) ----\n",
    "for i, c in enumerate(chunks[:2]):\n",
    "    print(f\"\\nğŸ§© Chunk {i+1}:\\n{c.page_content[:300]}...\")\n",
    "\n",
    "# ---- 5) (Optional) Save chunks for reuse later ----\n",
    "CHUNKS_PATH = DATA_DIR / \"hr_policy_chunks.pkl\"\n",
    "with open(CHUNKS_PATH, \"wb\") as f:\n",
    "    pickle.dump(chunks, f)\n",
    "\n",
    "print(f\"\\nğŸ’¾ Chunks saved to: {CHUNKS_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e168c1c-ed79-4a0e-a926-faadc28dade6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pysqlite3-binary in ./.local/lib/python3.10/site-packages (0.5.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mâœ… Patched sqlite3 with pysqlite3 backend.\n"
     ]
    }
   ],
   "source": [
    "!pip install pysqlite3-binary\n",
    "# ---- Patch SQLite if too old ----\n",
    "try:\n",
    "    import sqlite3\n",
    "    import pysqlite3\n",
    "    import sys\n",
    "    sys.modules[\"sqlite3\"] = sys.modules.pop(\"pysqlite3\")\n",
    "    print(\"âœ… Patched sqlite3 with pysqlite3 backend.\")\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ Could not patch sqlite3, fallback to system version:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580d3116-e13b-4f1a-abc5-da4aed5a2d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: module 'chromadb' has no attribute 'get_settings'\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: module 'chromadb' has no attribute 'get_settings'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¢ Creating text embeddings using OpenAI (in-memory mode)...\n",
      "âœ… Loaded 20 chunks from disk\n",
      "âœ… Using in-memory Chroma client (no file-system writes).\n",
      "âœ… Vector store built completely in memory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: module 'chromadb' has no attribute 'get_settings'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Retrieval test results:\n",
      "\n",
      "Result 1:\n",
      "The NestlÃ© Human Resources Policy\n",
      "4\n",
      "Learning is part of the Company culture.\n",
      "Employees at all levels are systematically \n",
      "encouraged to consider how they upgrade their \n",
      "knowledge and skills.\n",
      "The Company determines training and deve-\n",
      "lopment priorities. The responsibility for turning \n",
      "these into actions is shared between employees, \n",
      "line managers and the Human Resources. \n",
      "Experience and on-the-job t...\n",
      "\n",
      "Result 2:\n",
      "teams are encouraged to acquire additional skills, \n",
      "enrich job content and widen accountability.\n",
      "NestlÃ© also offers a comprehensive range of \n",
      "training activities and methodologies to support \n",
      "everyoneâ€™s learning and growth. Attending \n",
      "a programme should never be considered \n",
      "as a reward but as a component of on-going \n",
      "development.\n",
      "Additionally, corporate leadership programmes \n",
      "help us develop and r...\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# STEP 3 â€” EMBEDDINGS + IN-MEMORY VECTOR DB (Final Fixed)\n",
    "# ===============================\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import chromadb\n",
    "\n",
    "print(\"ğŸ”¢ Creating text embeddings using OpenAI (in-memory mode)...\")\n",
    "\n",
    "# Defining chunk path\n",
    "import pickle, pathlib\n",
    "CHUNKS_PATH = pathlib.Path(\"hr_policy_chunks.pkl\")\n",
    "with open(CHUNKS_PATH, \"rb\") as f:\n",
    "    chunks = pickle.load(f)\n",
    "print(f\"âœ… Loaded {len(chunks)} chunks from disk\")\n",
    "\n",
    "\n",
    "# 1ï¸âƒ£ Create embeddings\n",
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 2ï¸âƒ£ Use in-memory Chroma client (no disk writes)\n",
    "client = chromadb.Client()\n",
    "print(\"âœ… Using in-memory Chroma client (no file-system writes).\")\n",
    "\n",
    "# 3ï¸âƒ£ Build vector store\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_function,\n",
    "    client=client,\n",
    "    collection_name=\"hr_policy_memory\"\n",
    ")\n",
    "print(\"âœ… Vector store built completely in memory.\")\n",
    "\n",
    "# 4ï¸âƒ£ Test retrieval with the new API\n",
    "sample_query = \"What is the policy on employee training and development?\"\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})\n",
    "results = retriever.invoke(sample_query)  # <-- modern method\n",
    "\n",
    "print(\"\\nğŸ” Retrieval test results:\")\n",
    "for i, doc in enumerate(results, start=1):\n",
    "    print(f\"\\nResult {i}:\\n{doc.page_content[:400]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca2bbcbf-9989-4105-9bc9-0c3e675aa147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Question: What does the HR policy say about employee relations?\n",
      "ğŸ’¬ Answer: The HR policy emphasizes the importance of fair and constructive dialogues between the company and employee representatives, overcoming difficulties, reaching sustainable agreements, and implementing them. It also mentions the commitment to establishing flat and flexible structures with minimal levels of management and broad spans of control to enable people development, increase efficiency, and ease implementation of the \"NestlÃ© Management and Leadership Principles.\"\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# STEP 4 â€” QUESTIONâ€“ANSWER CHAIN\n",
    "# ============================\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1ï¸âƒ£  Initialize GPT model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "\n",
    "# 2ï¸âƒ£  Define a clear prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an AI-powered HR Assistant.\n",
    "Answer the question strictly using the context provided below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "If the answer is not contained in the context, respond:\n",
    "\"I couldnâ€™t find this information in the HR policy document.\"\n",
    "\"\"\")\n",
    "\n",
    "# 3ï¸âƒ£  Build the retrieval + generation pipeline\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Combine:  user question â†’ retrieve â†’ format â†’ LLM â†’ output\n",
    "qa_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 4ï¸âƒ£  Test the pipeline\n",
    "query = \"What does the HR policy say about employee relations?\"\n",
    "response = qa_chain.invoke(query)\n",
    "\n",
    "print(\"ğŸ” Question:\", query)\n",
    "print(\"ğŸ’¬ Answer:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e6f996f-c64d-4e59-ab23-2318fbe57784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.29.0, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://bba31dc3dcb3354df4.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://bba31dc3dcb3354df4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
      "----\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# STEP 5 â€” GRADIO CHATBOT UI\n",
    "# ============================\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "# --- 1ï¸âƒ£  Chatbot function ---\n",
    "def hr_chatbot(user_query):\n",
    "    \"\"\"\n",
    "    Receives a user's question, routes it through the retrieval+LLM chain,\n",
    "    and returns the answer.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = qa_chain.invoke(user_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"âš ï¸ Error: {str(e)}\"\n",
    "\n",
    "\n",
    "# --- 2ï¸âƒ£  Gradio interface layout ---\n",
    "chat_ui = gr.Interface(\n",
    "    fn=hr_chatbot,\n",
    "    inputs=gr.Textbox(\n",
    "        lines=2,\n",
    "        placeholder=\"Ask a question about the HR policy...\",\n",
    "        label=\"ğŸ’¬ Your Question\"\n",
    "    ),\n",
    "    outputs=gr.Textbox(\n",
    "        label=\"ğŸ¤– HR Assistant Answer\"\n",
    "    ),\n",
    "    title=\"AI-Powered HR Assistant\",\n",
    "    description=(\n",
    "        \"Ask any question related to the HR policy document. \"\n",
    "        \"The assistant uses OpenAI GPT-3.5-Turbo with document-aware retrieval.\"\n",
    "    ),\n",
    "    examples=[\n",
    "        [\"What does the policy say about employee training?\"],\n",
    "        [\"Explain the companyâ€™s stance on work-life balance.\"],\n",
    "        [\"How are performance evaluations conducted?\"]\n",
    "    ],\n",
    ")\n",
    "\n",
    "# --- 3ï¸âƒ£  Launch the web interface ---\n",
    "chat_ui.launch(share=True)     # gives a public link\n",
    "# OR, for Jupyter inline display\n",
    "chat_ui.launch(inline=True)\n",
    "\n",
    "#chat_ui.launch(debug=True, share=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed087798-17fd-4aa9-b039-e7a989b722ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting gradio==4.29.0\n",
      "  Downloading gradio-4.29.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio==4.29.0)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio==4.29.0)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fastapi (from gradio==4.29.0)\n",
      "  Downloading fastapi-0.121.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting ffmpy (from gradio==4.29.0)\n",
      "  Downloading ffmpy-0.6.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==0.16.1 (from gradio==4.29.0)\n",
      "  Downloading gradio_client-0.16.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio==4.29.0)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting huggingface-hub>=0.19.3 (from gradio==4.29.0)\n",
      "  Downloading huggingface_hub-1.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio==4.29.0)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting jinja2<4.0 (from gradio==4.29.0)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting markupsafe~=2.0 (from gradio==4.29.0)\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting matplotlib~=3.0 (from gradio==4.29.0)\n",
      "  Downloading matplotlib-3.10.7-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting numpy~=1.0 (from gradio==4.29.0)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting orjson~=3.0 (from gradio==4.29.0)\n",
      "  Using cached orjson-3.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting packaging (from gradio==4.29.0)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pandas<3.0,>=1.0 (from gradio==4.29.0)\n",
      "  Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting pillow<11.0,>=8.0 (from gradio==4.29.0)\n",
      "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pydantic>=2.0 (from gradio==4.29.0)\n",
      "  Using cached pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting pydub (from gradio==4.29.0)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio==4.29.0)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyyaml<7.0,>=5.0 (from gradio==4.29.0)\n",
      "  Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting ruff>=0.2.2 (from gradio==4.29.0)\n",
      "  Downloading ruff-0.14.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==4.29.0)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio==4.29.0)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio==4.29.0)\n",
      "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting typing-extensions~=4.0 (from gradio==4.29.0)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting urllib3~=2.0 (from gradio==4.29.0)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio==4.29.0)\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting fsspec (from gradio-client==0.16.1->gradio==4.29.0)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.1->gradio==4.29.0)\n",
      "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<6.0,>=4.2.0->gradio==4.29.0)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6.0,>=4.2.0->gradio==4.29.0)\n",
      "  Downloading narwhals-2.10.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio==4.29.0)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio==4.29.0)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio==4.29.0)\n",
      "  Downloading fonttools-4.60.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib~=3.0->gradio==4.29.0)\n",
      "  Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib~=3.0->gradio==4.29.0)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib~=3.0->gradio==4.29.0)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio==4.29.0)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio==4.29.0)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio==4.29.0)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio==4.29.0)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio==4.29.0)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting anyio (from httpx>=0.24.1->gradio==4.29.0)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx>=0.24.1->gradio==4.29.0)\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio==4.29.0)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.24.1->gradio==4.29.0)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.24.1->gradio==4.29.0)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.19.3->gradio==4.29.0)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.19.3->gradio==4.29.0)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typer-slim (from huggingface-hub>=0.19.3->gradio==4.29.0)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub>=0.19.3->gradio==4.29.0)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0)\n",
      "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0)\n",
      "  Downloading rpds_py-0.28.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio==4.29.0)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic>=2.0->gradio==4.29.0)\n",
      "  Using cached pydantic_core-2.41.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.0->gradio==4.29.0)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.29.0)\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0)\n",
      "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio->httpx>=0.24.1->gradio==4.29.0)\n",
      "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.24.1->gradio==4.29.0)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting starlette<0.50.0,>=0.40.0 (from fastapi->gradio==4.29.0)\n",
      "  Downloading starlette-0.49.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi->gradio==4.29.0)\n",
      "  Downloading annotated_doc-0.0.3-py3-none-any.whl.metadata (6.6 kB)\n",
      "Downloading gradio-4.29.0-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-0.16.1-py3-none-any.whl (314 kB)\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Downloading matplotlib-3.10.7-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached orjson-3.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
      "Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m770.3/770.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading huggingface_hub-1.0.1-py3-none-any.whl (503 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading narwhals-2.10.2-py3-none-any.whl (419 kB)\n",
      "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Using cached pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Using cached pydantic_core-2.41.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading rpds_py-0.28.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (382 kB)\n",
      "Downloading ruff-0.14.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Downloading fastapi-0.121.0-py3-none-any.whl (109 kB)\n",
      "Downloading starlette-0.49.3-py3-none-any.whl (74 kB)\n",
      "Downloading annotated_doc-0.0.3-py3-none-any.whl (5.5 kB)\n",
      "Downloading ffmpy-0.6.4-py3-none-any.whl (5.6 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pytz, pydub, websockets, urllib3, tzdata, typing-extensions, tqdm, tomlkit, sniffio, six, shellingham, semantic-version, ruff, rpds-py, pyyaml, python-multipart, pyparsing, pygments, pillow, packaging, orjson, numpy, narwhals, mdurl, markupsafe, kiwisolver, importlib-resources, idna, hf-xet, h11, fsspec, fonttools, filelock, ffmpy, cycler, click, certifi, attrs, annotated-types, annotated-doc, aiofiles, uvicorn, typing-inspection, typer-slim, referencing, python-dateutil, pydantic-core, markdown-it-py, jinja2, httpcore, exceptiongroup, contourpy, rich, pydantic, pandas, matplotlib, jsonschema-specifications, anyio, typer, starlette, jsonschema, httpx, huggingface-hub, fastapi, altair, gradio-client, gradio\n",
      "\u001b[2K  Attempting uninstall: typing-extensionsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/67\u001b[0m [tzdata]]ts]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.15.0â”â”â”â”â”\u001b[0m \u001b[32m 4/67\u001b[0m [tzdata]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.15.0:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/67\u001b[0m [tzdata]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.15.0â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/67\u001b[0m [typing-extensions]\n",
      "\u001b[2K   \u001b[91mâ”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/67\u001b[0m [tqdm]g-extensions]\u001b[33m  WARNING: The script tqdm is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17/67\u001b[0m [pygments]]tipart]\u001b[33m  WARNING: The script pygmentize is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: orjson[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19/67\u001b[0m [packaging]\n",
      "\u001b[2K    Found existing installation: orjson 3.11.4â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19/67\u001b[0m [packaging]\n",
      "\u001b[2K    Uninstalling orjson-3.11.4:90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19/67\u001b[0m [packaging]\n",
      "\u001b[2K      Successfully uninstalled orjson-3.11.4â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19/67\u001b[0m [packaging]\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20/67\u001b[0m [orjson]\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/voc/work/.local/lib/python3.10/site-packages/~rjson'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21/67\u001b[0m [numpy]\u001b[33m  WARNING: The script f2py is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31/67\u001b[0m [fonttools]resources]\u001b[33m  WARNING: The scripts fonttools, pyftmerge, pyftsubset and ttx are installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41/67\u001b[0m [uvicorn]]-types]\u001b[33m  WARNING: The script uvicorn is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: typing-inspection\n",
      "\u001b[2K    Found existing installation: typing-inspection 0.4.2â”â”â”â”â”â”\u001b[0m \u001b[32m41/67\u001b[0m [uvicorn]\n",
      "\u001b[2K    Uninstalling typing-inspection-0.4.2:mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42/67\u001b[0m [typing-inspection]\n",
      "\u001b[2K      Successfully uninstalled typing-inspection-0.4.2â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42/67\u001b[0m [typing-inspection]\n",
      "\u001b[2K  Attempting uninstall: pydantic-corem\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45/67\u001b[0m [python-dateutil]n]\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.41.4â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45/67\u001b[0m [python-dateutil]\n",
      "\u001b[2K    Uninstalling pydantic_core-2.41.4:mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45/67\u001b[0m [python-dateutil]\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.41.4â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45/67\u001b[0m [python-dateutil]\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46/67\u001b[0m [pydantic-core]\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/voc/work/.local/lib/python3.10/site-packages/~ydantic_core'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47/67\u001b[0m [markdown-it-py]\u001b[33m  WARNING: The script markdown-it is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: pydanticâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52/67\u001b[0m [rich]urpy]roup]\n",
      "\u001b[2K    Found existing installation: pydantic 2.12.3m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52/67\u001b[0m [rich]\n",
      "\u001b[2K    Uninstalling pydantic-2.12.3:â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53/67\u001b[0m [pydantic]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.12.31mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53/67\u001b[0m [pydantic]\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m58/67\u001b[0m [typer]hema-specifications]\u001b[33m  WARNING: The script typer is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m60/67\u001b[0m [jsonschema]\u001b[33m  WARNING: The script jsonschema is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: httpx\n",
      "\u001b[2K    Found existing installation: httpx 0.28.191mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m60/67\u001b[0m [jsonschema]\n",
      "\u001b[2K    Uninstalling httpx-0.28.1:â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m60/67\u001b[0m [jsonschema]\n",
      "\u001b[2K      Successfully uninstalled httpx-0.28.1â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”\u001b[0m \u001b[32m61/67\u001b[0m [httpx]]\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”\u001b[0m \u001b[32m61/67\u001b[0m [httpx]\u001b[33m  WARNING: The script httpx is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”\u001b[0m \u001b[32m62/67\u001b[0m [huggingface-hub]\u001b[33m  WARNING: The scripts hf and tiny-agents are installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”\u001b[0m \u001b[32m63/67\u001b[0m [fastapi]ace-hub]\u001b[33m  WARNING: The script fastapi is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m66/67\u001b[0m [gradio] [gradio-client]\u001b[33m  WARNING: The scripts gradio and upload_theme are installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67/67\u001b[0m [gradio]\n",
      "\u001b[1A\u001b[2K\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyquil 3.3.3 requires qcs-api-client<0.22.0,>=0.21.0, which is not installed.\n",
      "pennylane 0.32.0 requires numpy<1.24, but you have numpy 1.26.4 which is incompatible.\n",
      "awswrangler 3.4.2 requires packaging<24.0,>=21.1, but you have packaging 25.0 which is incompatible.\n",
      "botocore 1.27.20 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.5.0 which is incompatible.\n",
      "confection 0.0.4 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.12.3 which is incompatible.\n",
      "dp-accounting 0.4.3 requires absl-py~=1.0, but you have absl-py 2.0.0 which is incompatible.\n",
      "dwave-networkx 0.8.12 requires networkx<3.0,>=2.4, but you have networkx 3.2.1 which is incompatible.\n",
      "google-vizier 0.1.11 requires attrs==23.1.0, but you have attrs 25.4.0 which is incompatible.\n",
      "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.20 which is incompatible.\n",
      "jupytext 1.13.8 requires markdown-it-py<3.0.0,>=1.0.0, but you have markdown-it-py 4.0.0 which is incompatible.\n",
      "kubernetes 28.1.0 requires urllib3<2.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "mdit-py-plugins 0.3.0 requires markdown-it-py<3.0.0,>=1.0.0, but you have markdown-it-py 4.0.0 which is incompatible.\n",
      "panel 0.12.7 requires setuptools<61,>=42, but you have setuptools 69.0.2 which is incompatible.\n",
      "pegasus-wms-common 5.0.1 requires PyYAML<5.5,>5.3, but you have pyyaml 6.0.3 which is incompatible.\n",
      "pyquil 3.3.3 requires lark<0.12.0,>=0.11.1, but you have lark 1.1.8 which is incompatible.\n",
      "pyquil 3.3.3 requires networkx<3.0,>=2.5, but you have networkx 3.2.1 which is incompatible.\n",
      "quick-start 0.0.dev10 requires appdirs==1.4.3, but you have appdirs 1.4.4 which is incompatible.\n",
      "quick-start 0.0.dev10 requires Click==7.0, but you have click 8.3.0 which is incompatible.\n",
      "selenium 4.3.0 requires urllib3[secure,socks]~=1.26, but you have urllib3 2.5.0 which is incompatible.\n",
      "spacy 3.5.1 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.12.3 which is incompatible.\n",
      "spacy 3.5.1 requires typer<0.8.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.\n",
      "streamlit 1.28.2 requires packaging<24,>=16.8, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.28.2 requires rich<14,>=10.14.0, but you have rich 14.2.0 which is incompatible.\n",
      "tensorboard 2.13.0 requires google-auth-oauthlib<1.1,>=0.5, but you have google-auth-oauthlib 1.1.0 which is incompatible.\n",
      "tensorflow 2.13.1 requires numpy<=1.24.3,>=1.22, but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow 2.13.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.15.0 which is incompatible.\n",
      "tensorflow-federated 0.63.0 requires absl-py==1.*,>=1.0, but you have absl-py 2.0.0 which is incompatible.\n",
      "tensorflow-federated 0.63.0 requires attrs~=23.1, but you have attrs 25.4.0 which is incompatible.\n",
      "tensorflow-federated 0.63.0 requires scipy~=1.9.3, but you have scipy 1.11.4 which is incompatible.\n",
      "tensorflow-federated 0.63.0 requires typing-extensions==4.5.*,>=4.5.0, but you have typing-extensions 4.15.0 which is incompatible.\n",
      "tensorflow-model-optimization 0.7.5 requires absl-py~=1.2, but you have absl-py 2.0.0 which is incompatible.\n",
      "tensorflow-privacy 0.8.11 requires absl-py==1.*,>=1.0, but you have absl-py 2.0.0 which is incompatible.\n",
      "tensorflow-privacy 0.8.11 requires packaging~=22.0, but you have packaging 25.0 which is incompatible.\n",
      "tensorflow-privacy 0.8.11 requires pandas~=1.4, but you have pandas 2.3.3 which is incompatible.\n",
      "thinc 8.1.9 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.12.3 which is incompatible.\n",
      "tokenizers 0.15.0 requires huggingface_hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "transformers 4.35.2 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "virtualenv 20.15.1 requires platformdirs<3,>=2, but you have platformdirs 4.0.0 which is incompatible.\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\n",
      "ydata-profiling 4.5.1 requires pandas!=1.4.0,<2.1,>1.1, but you have pandas 2.3.3 which is incompatible.\n",
      "ydata-profiling 4.5.1 requires pydantic<2,>=1.8.1, but you have pydantic 2.12.3 which is incompatible.\n",
      "ypy-websocket 0.8.2 requires aiofiles<23,>=22.1.0, but you have aiofiles 23.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-23.2.1 altair-5.5.0 annotated-doc-0.0.3 annotated-types-0.7.0 anyio-4.11.0 attrs-25.4.0 certifi-2025.10.5 click-8.3.0 contourpy-1.3.2 cycler-0.12.1 exceptiongroup-1.3.0 fastapi-0.121.0 ffmpy-0.6.4 filelock-3.20.0 fonttools-4.60.1 fsspec-2025.10.0 gradio-4.29.0 gradio-client-0.16.1 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-1.0.1 idna-3.11 importlib-resources-6.5.2 jinja2-3.1.6 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 kiwisolver-1.4.9 markdown-it-py-4.0.0 markupsafe-2.1.5 matplotlib-3.10.7 mdurl-0.1.2 narwhals-2.10.2 numpy-1.26.4 orjson-3.11.4 packaging-25.0 pandas-2.3.3 pillow-10.4.0 pydantic-2.12.3 pydantic-core-2.41.4 pydub-0.25.1 pygments-2.19.2 pyparsing-3.2.5 python-dateutil-2.9.0.post0 python-multipart-0.0.20 pytz-2025.2 pyyaml-6.0.3 referencing-0.37.0 rich-14.2.0 rpds-py-0.28.0 ruff-0.14.3 semantic-version-2.10.0 shellingham-1.5.4 six-1.17.0 sniffio-1.3.1 starlette-0.49.3 tomlkit-0.12.0 tqdm-4.67.1 typer-0.20.0 typer-slim-0.20.0 typing-extensions-4.15.0 typing-inspection-0.4.2 tzdata-2025.2 urllib3-2.5.0 uvicorn-0.38.0 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade --force-reinstall \"gradio==4.29.0\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00efed5b-db79-4c6b-8e4b-f5db6472cc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting huggingface_hub==0.24.5\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from huggingface_hub==0.24.5)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub==0.24.5)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting packaging>=20.9 (from huggingface_hub==0.24.5)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pyyaml>=5.1 (from huggingface_hub==0.24.5)\n",
      "  Using cached pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting requests (from huggingface_hub==0.24.5)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface_hub==0.24.5)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub==0.24.5)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->huggingface_hub==0.24.5)\n",
      "  Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->huggingface_hub==0.24.5)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface_hub==0.24.5)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->huggingface_hub==0.24.5)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Using cached pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: urllib3, typing-extensions, tqdm, pyyaml, packaging, idna, fsspec, filelock, charset_normalizer, certifi, requests, huggingface_hub\n",
      "\u001b[2K  Attempting uninstall: urllib3\n",
      "\u001b[2K    Found existing installation: urllib3 2.5.0\n",
      "\u001b[2K    Uninstalling urllib3-2.5.0:\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.5.0\n",
      "\u001b[2K  Attempting uninstall: typing-extensionsâ”â”â”â”â”â”â”\u001b[0m \u001b[32m 0/12\u001b[0m [urllib3]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.15.012\u001b[0m [urllib3]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.15.0:â”â”\u001b[0m \u001b[32m 0/12\u001b[0m [urllib3]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.15.0â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/12\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: tqdm0mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/12\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: tqdm 4.67.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/12\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling tqdm-4.67.1:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/12\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled tqdm-4.67.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/12\u001b[0m [typing-extensions]\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/12\u001b[0m [tqdm]\u001b[33m  WARNING: The script tqdm is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: pyyaml90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/12\u001b[0m [tqdm]\n",
      "\u001b[2K    Found existing installation: PyYAML 6.0.3â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/12\u001b[0m [tqdm]\n",
      "\u001b[2K    Uninstalling PyYAML-6.0.3:0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/12\u001b[0m [pyyaml]\n",
      "\u001b[2K      Successfully uninstalled PyYAML-6.0.3â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/12\u001b[0m [pyyaml]\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/12\u001b[0m [pyyaml]\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/voc/work/.local/lib/python3.10/site-packages/~aml'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: packaging\n",
      "\u001b[2K    Found existing installation: packaging 25.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/12\u001b[0m [pyyaml]\n",
      "\u001b[2K    Uninstalling packaging-25.0:[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/12\u001b[0m [packaging]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/12\u001b[0m [packaging]\n",
      "\u001b[2K  Attempting uninstall: idna0mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/12\u001b[0m [packaging]\n",
      "\u001b[2K    Found existing installation: idna 3.11â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/12\u001b[0m [packaging]\n",
      "\u001b[2K    Uninstalling idna-3.11:\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/12\u001b[0m [packaging]\n",
      "\u001b[2K      Successfully uninstalled idna-3.11â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/12\u001b[0m [packaging]\n",
      "\u001b[2K  Attempting uninstall: fsspec91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/12\u001b[0m [idna]]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.10.0â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/12\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling fsspec-2025.10.0:90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/12\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.10.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/12\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: filelock\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/12\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: filelock 3.20.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/12\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling filelock-3.20.0:â•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/12\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled filelock-3.20.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/12\u001b[0m [fsspec]\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/12\u001b[0m [charset_normalizer]\u001b[33m  WARNING: The script normalizer is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: certifi\n",
      "\u001b[2K    Found existing installation: certifi 2025.10.5â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/12\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling certifi-2025.10.5:[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/12\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled certifi-2025.10.5\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/12\u001b[0m [certifi]alizer]\n",
      "\u001b[2K  Attempting uninstall: requestsâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/12\u001b[0m [certifi]\n",
      "\u001b[2K    Found existing installation: requests 2.32.5\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/12\u001b[0m [certifi]\n",
      "\u001b[2K    Uninstalling requests-2.32.5:â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m10/12\u001b[0m [requests]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.5â•º\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m10/12\u001b[0m [requests]\n",
      "\u001b[2K  Attempting uninstall: huggingface_hubâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m10/12\u001b[0m [requests]\n",
      "\u001b[2K    Found existing installation: huggingface-hub 1.0.10mâ”â”â”â”â”â”\u001b[0m \u001b[32m10/12\u001b[0m [requests]\n",
      "\u001b[2K    Uninstalling huggingface-hub-1.0.1:â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”\u001b[0m \u001b[32m11/12\u001b[0m [huggingface_hub]\n",
      "\u001b[2K      Successfully uninstalled huggingface-hub-1.0.10m\u001b[90mâ”â”â”\u001b[0m \u001b[32m11/12\u001b[0m [huggingface_hub]\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”\u001b[0m \u001b[32m11/12\u001b[0m [huggingface_hub]\u001b[33m  WARNING: The script huggingface-cli is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12/12\u001b[0m [huggingface_hub] [huggingface_hub]\n",
      "\u001b[1A\u001b[2K\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/voc/work/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pennylane 0.32.0 requires numpy<1.24, but you have numpy 1.26.4 which is incompatible.\n",
      "awswrangler 3.4.2 requires packaging<24.0,>=21.1, but you have packaging 25.0 which is incompatible.\n",
      "botocore 1.27.20 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.5.0 which is incompatible.\n",
      "confection 0.0.4 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.12.3 which is incompatible.\n",
      "jupytext 1.13.8 requires markdown-it-py<3.0.0,>=1.0.0, but you have markdown-it-py 4.0.0 which is incompatible.\n",
      "kubernetes 28.1.0 requires urllib3<2.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "panel 0.12.7 requires setuptools<61,>=42, but you have setuptools 69.0.2 which is incompatible.\n",
      "pegasus-wms-common 5.0.1 requires PyYAML<5.5,>5.3, but you have pyyaml 6.0.3 which is incompatible.\n",
      "selenium 4.3.0 requires urllib3[secure,socks]~=1.26, but you have urllib3 2.5.0 which is incompatible.\n",
      "spacy 3.5.1 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.12.3 which is incompatible.\n",
      "spacy 3.5.1 requires typer<0.8.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.\n",
      "streamlit 1.28.2 requires packaging<24,>=16.8, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.28.2 requires rich<14,>=10.14.0, but you have rich 14.2.0 which is incompatible.\n",
      "tensorboard 2.13.0 requires google-auth-oauthlib<1.1,>=0.5, but you have google-auth-oauthlib 1.1.0 which is incompatible.\n",
      "tensorflow 2.13.1 requires numpy<=1.24.3,>=1.22, but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow 2.13.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.15.0 which is incompatible.\n",
      "tensorflow-federated 0.63.0 requires absl-py==1.*,>=1.0, but you have absl-py 2.0.0 which is incompatible.\n",
      "tensorflow-federated 0.63.0 requires attrs~=23.1, but you have attrs 25.4.0 which is incompatible.\n",
      "tensorflow-federated 0.63.0 requires scipy~=1.9.3, but you have scipy 1.11.4 which is incompatible.\n",
      "tensorflow-federated 0.63.0 requires typing-extensions==4.5.*,>=4.5.0, but you have typing-extensions 4.15.0 which is incompatible.\n",
      "tensorflow-privacy 0.8.11 requires absl-py==1.*,>=1.0, but you have absl-py 2.0.0 which is incompatible.\n",
      "tensorflow-privacy 0.8.11 requires packaging~=22.0, but you have packaging 25.0 which is incompatible.\n",
      "tensorflow-privacy 0.8.11 requires pandas~=1.4, but you have pandas 2.3.3 which is incompatible.\n",
      "thinc 8.1.9 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.12.3 which is incompatible.\n",
      "virtualenv 20.15.1 requires platformdirs<3,>=2, but you have platformdirs 4.0.0 which is incompatible.\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\n",
      "ydata-profiling 4.5.1 requires pandas!=1.4.0,<2.1,>1.1, but you have pandas 2.3.3 which is incompatible.\n",
      "ydata-profiling 4.5.1 requires pydantic<2,>=1.8.1, but you have pydantic 2.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed certifi-2025.10.5 charset_normalizer-3.4.4 filelock-3.20.0 fsspec-2025.10.0 huggingface_hub-0.24.5 idna-3.11 packaging-25.0 pyyaml-6.0.3 requests-2.32.5 tqdm-4.67.1 typing-extensions-4.15.0 urllib3-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall \"huggingface_hub==0.24.5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5646355-3685-42f4-a609-5e2a908bc2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤–  Evaluating AI-Powered HR Assistant...\n",
      "\n",
      "Q: What does the HR policy say about employee training?\n",
      "A: The HR policy emphasizes that learning is part of the company culture, and employees are encouraged to upgrade their knowledge and skills. The company determines training and development priorities, with responsibility shared between employees, line managers, and HR. Experience and on-the-job training are primary sources of learning, and managers are responsible for guiding and coaching employees to succeed in their current positions. Continuous improvement, sharing knowledge, and participating in training activities are also encouraged.\n",
      "â±  3.16s\n",
      "----------------------------------------------------------------------\n",
      "Q: How does the company ensure work-life balance?\n",
      "A: The company ensures work-life balance by providing flexible working conditions whenever possible, encouraging employees to have outside interests, especially community involvement, and supporting a better balance of private and professional life.\n",
      "â±  1.83s\n",
      "----------------------------------------------------------------------\n",
      "Q: Explain the policy on performance evaluation.\n",
      "A: The policy on performance evaluation involves setting challenging objectives, providing regular feedback, and using tools such as the Performance Evaluation process (PE), the Progress and Development Guide (PDG), and 360Â° assessments. Managers are responsible for monitoring objectives, coaching employees, acknowledging high performance, and managing low performance with integrity. Employees work with their line managers to ensure challenging objectives are set and effectively evaluated throughout the year.\n",
      "â±  2.06s\n",
      "----------------------------------------------------------------------\n",
      "Q: What is the approach towards diversity and inclusion?\n",
      "A: The approach towards diversity and inclusion at NestlÃ© involves removing barriers to career progression for women and men, developing a more flexible work environment, initiating mentoring schemes, having flexible career paths, and providing dual career support. The company is committed to ensuring sustainable conditions for a gender-balanced and diverse workforce.\n",
      "â±  2.11s\n",
      "----------------------------------------------------------------------\n",
      "Q: Who is responsible for employee safety?\n",
      "A: Line managers are responsible for employee safety according to the HR policy document provided.\n",
      "â±  1.82s\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# STEP 6 â€” TEST & EVALUATE CHATBOT\n",
    "# ============================\n",
    "\n",
    "import time\n",
    "\n",
    "# 1ï¸âƒ£  Define a few realistic HR questions\n",
    "test_questions = [\n",
    "    \"What does the HR policy say about employee training?\",\n",
    "    \"How does the company ensure work-life balance?\",\n",
    "    \"Explain the policy on performance evaluation.\",\n",
    "    \"What is the approach towards diversity and inclusion?\",\n",
    "    \"Who is responsible for employee safety?\"\n",
    "]\n",
    "\n",
    "# 2ï¸âƒ£  Run quick evaluation\n",
    "print(\"ğŸ¤–  Evaluating AI-Powered HR Assistant...\\n\")\n",
    "for q in test_questions:\n",
    "    start = time.time()\n",
    "    try:\n",
    "        ans = qa_chain.invoke(q)\n",
    "        print(f\"Q: {q}\\nA: {ans}\\nâ±  {time.time()-start:.2f}s\\n{'-'*70}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error on question: {q}\\n{e}\\n{'-'*70}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "581a2422-7328-4478-9715-19d58d560cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HR Assistant with manual memory ready.\n",
      "\n",
      "IMPORTANT: You are using gradio version 4.29.0, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://d0bfa38b4d76c3b7fb.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d0bfa38b4d76c3b7fb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======================================================\n",
    "# STEP 6 â€” FINAL PROJECT BLOCK (Manual Memory + Logging + Tests)\n",
    "# ======================================================\n",
    "\n",
    "import csv, datetime, time\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import gradio as gr\n",
    "\n",
    "# 1ï¸âƒ£ Simple manual memory (list-based)\n",
    "conversation_history = []  # stores tuples of (question, answer)\n",
    "\n",
    "def get_chat_history_text():\n",
    "    if not conversation_history:\n",
    "        return \"No previous conversation.\"\n",
    "    hist = \"\"\n",
    "    for q, a in conversation_history[-5:]:  # keep last 5 turns\n",
    "        hist += f\"User: {q}\\nAssistant: {a}\\n\"\n",
    "    return hist\n",
    "\n",
    "# 2ï¸âƒ£ Prompt template including previous chat\n",
    "prompt_with_history = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an AI-powered HR Assistant.\n",
    "Use ONLY the HR policy context below to answer accurately and concisely.\n",
    "Keep prior conversation in mind for continuity.\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "If the answer is not contained in the context, respond:\n",
    "\"I couldnâ€™t find this information in the HR policy document.\"\n",
    "\"\"\")\n",
    "\n",
    "# 3ï¸âƒ£ Build full chain\n",
    "qa_with_history = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"chat_history\": lambda _: get_chat_history_text(),\n",
    "    }\n",
    "    | prompt_with_history\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"âœ… HR Assistant with manual memory ready.\\n\")\n",
    "\n",
    "# 4ï¸âƒ£ CSV logging\n",
    "LOG_FILE = \"chat_log.csv\"\n",
    "def log_interaction(question, answer):\n",
    "    with open(LOG_FILE, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        csv.writer(f).writerow([datetime.datetime.now(), question, answer])\n",
    "\n",
    "# 5ï¸âƒ£ Chatbot function\n",
    "def hr_chatbot(user_query):\n",
    "    try:\n",
    "        result = qa_with_history.invoke(user_query)\n",
    "        conversation_history.append((user_query, result))\n",
    "        log_interaction(user_query, result)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"âš ï¸ Error: {e}\"\n",
    "\n",
    "# 6ï¸âƒ£ Gradio interface\n",
    "chat_ui = gr.Interface(\n",
    "    fn=hr_chatbot,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Ask about HR policy...\"),\n",
    "    outputs=gr.Textbox(label=\"ğŸ¤– HR Assistant Answer\"),\n",
    "    title=\"AI-Powered HR Assistant with Memory\",\n",
    "    description=\"Chat with an HR Assistant powered by OpenAI GPT-3.5 and your HR policy document.\",\n",
    "    examples=[\n",
    "        [\"What does the policy say about employee training?\"],\n",
    "        [\"Who ensures workplace safety?\"],\n",
    "        [\"Explain the policy on performance evaluation.\"]\n",
    "    ],\n",
    ")\n",
    "\n",
    "chat_ui.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
